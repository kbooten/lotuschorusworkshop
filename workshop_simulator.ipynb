{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVRYhX51Tfzy"
      },
      "source": [
        "# Lotus Chorus Workshop \n",
        "\n",
        ">*a* γυμνάσιον\n",
        "\n",
        ">*for Helen Zell*\n",
        "\n",
        "To run this notebook, select from above ***Runtime>Run all***. The interactive dialogue will appear at the bottom of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SAIVrlJXYKgD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "pip install nltk==3.6.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BDvyP6A5a271"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import nltk\n",
        "nltk.download('book')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk import tokenize,pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UbZQ9XRk-Ang"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "pip install spacy==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KUIMWwRp-I1w"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4-zyGcQo-P4O"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MPK6XyoL-vdw"
      },
      "outputs": [],
      "source": [
        "def toktag(text):\n",
        "  \"\"\"\n",
        "  utility function to tokenize and pos_tag\n",
        "  using spacy but in nltk tuple style\n",
        "  \"\"\"\n",
        "  return [(i.text,i.tag_) for i in nlp(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vk5QQF9XTsjD"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1H5rFrNBXwt",
        "outputId": "02b7ef22-ef78-45d6-8c1d-f0621bbf1346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 1, 4, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def randrand(alist,min=1):\n",
        "  \"\"\"\n",
        "  utility function to randomly sample\n",
        "  a random number of elements from a list\n",
        "  \"\"\"\n",
        "  n = random.randint(min,len(alist))\n",
        "  return random.sample(alist,n)\n",
        "\n",
        "\n",
        "randrand([1,2,3,4,5],min=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ3_UPyFU5sQ"
      },
      "source": [
        "**Comment on noun:** template-based approach to commenting on a noun\n",
        "\n",
        "Template includes words from WordNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QsF_t_GGi-Vw"
      },
      "outputs": [],
      "source": [
        "simple_noun_recommendations = [#what if the <targetNN> were more <JJ>?\",\n",
        "                               'What about \"<JJ> <targetNN>\"? Or \"<JJ> <targetNN>\"?',\n",
        "                               'In my opinion, the word \"<targetNN>\" is a bit too <JJneg>.',\n",
        "                               'I feel like you could replace \"<targetNN>\" with something a bit more <JJpos>?',\n",
        "                               #\"what if the <targetNN> were <JJ>, maybe even like a <NN>?\",\n",
        "                               #Boring. What if you replaced \"<targetNN>\" with <NN>?'\n",
        "                               #\"'<targetNN>'?  What if this were the opposite?\"\n",
        "                               ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "REp6Dhx2RmfU"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGlkzAGURp_t",
        "outputId": "a8cb71df-032c-4c3a-cae4-8926753aabbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82115"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "nouns = [i.lemma_names()[0].replace(\"_\",\" \") for i in list(wn.all_synsets('n'))]\n",
        "len(nouns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCe2t4hoS0li",
        "outputId": "94d84596-b4af-4735-b42b-55b177952046"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18156"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "adjectives = [i.lemma_names()[0].replace(\"_\",\" \") for i in list(wn.all_synsets(\"a\"))]\n",
        "len(adjectives)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kIHxKHtWlbEy"
      },
      "outputs": [],
      "source": [
        "# myNN = [\"wolf\",\"person\",\"machine\",\"orbit\",\"fancy\",\"past\",\"future\",\"clothing\",\"toy\",\n",
        "#         \"idea\",\"interiority\",\"dream\",\"path\",\"virtue\",\"sin\",\"polital perspective\",\"language\",\"superego\",\"ego\",\"id\",\"shampoo\",\"education\"]\n",
        "# my\n",
        "\n",
        "myNN = nouns#_nn_clean\n",
        "myJJ = adjectives#_jj_clean\n",
        "JJneg = [\"florid\",\"petite\",\"grim\",\"long\",\n",
        "           \"trite\",\"honeyed\",\"brittle\",\n",
        "           \"happy\",\"postmodern\",\"mainstream\",\n",
        "           \"expected\",\"quirky\",\"soft\",\"salty\",\"anthropomorphic\",\"academic\",\n",
        "           \"North American\",\"old\",\"phallic\",\"representational\",\"abstract\",\"polysemic\",\"simple\"]\n",
        "\n",
        "JJpos = [\"erudite\",\"crisp\",\"evocative\",\"neutral\",\"global\",\"critical\",\n",
        "         \"self-aware\",\"ironic\",\"careful\",\"polysemous\",\"deep\",\"emotionally resonant\",\"politically important\",\"deserved\",\"ambivalent\",\n",
        "         \"contemporary\",\"specific\",\"true to your life\",\"holy\",\"holy\",\"holy\",\"reverent\"\n",
        "         ]\n",
        "\n",
        "tag2options = {\"NN\":myNN,\"JJ\":myJJ,\"JJneg\":JJneg,\"JJpos\":JJpos}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QqlYMo_Wj5Ce",
        "outputId": "4d09d6de-b7c9-4e15-98b2-5e6227f6ee8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What about \"sexless <targetNN>\"? Or \"sad <targetNN>\"?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "def generate_simple_noun_rec():\n",
        "  template = random.choice(simple_noun_recommendations)\n",
        "  to_replace = [t for t in re.findall(r'(?:<)([A-Za-z]{1,})(?:>)',template) if t.startswith('target')==False]\n",
        "  for tag in to_replace:\n",
        "    template = template.replace(\"<\"+tag+\">\",random.choice(tag2options[tag]),1)\n",
        "  return template\n",
        "\n",
        "\n",
        "generate_simple_noun_rec()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "t2f90Hcwb-UD",
        "outputId": "31b2e88f-3828-4645-d205-5d36c5a3f474"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I feel like you could replace \"dog\" with something a bit more polysemous?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def COMMENT_NN_recommendation(line):\n",
        "  pos_tagged = toktag(line)\n",
        "  nouns = [token for token,tag in pos_tagged if tag==\"NN\"]\n",
        "  if len(nouns)<1:\n",
        "    return\n",
        "  noun = random.choice(nouns)\n",
        "  template = generate_simple_noun_rec()\n",
        "  template = template.replace(\"<targetNN>\",noun.lower())\n",
        "  return template\n",
        "  \n",
        "COMMENT_NN_recommendation(\"The dog is in the cave.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RagWNz6uZ3MR"
      },
      "source": [
        "**Comment on noun via Wikipedia:** suggests a related rare/specific word from the key term's Wikipedia page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gG7XAb6Gb2ZE"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3xoRHE3BaE3a"
      },
      "outputs": [],
      "source": [
        "page = requests.get(\"https://en.wikipedia.org/wiki/Skin\")\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8n0lPyZbe5Ze"
      },
      "outputs": [],
      "source": [
        "wikitext = \" \".join([s.getText() for s in soup([\"p\"])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "zuaahP14f-SE",
        "outputId": "1dd2244a-5c39-442a-d381-ffac295533ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Skin is the layer of usually soft, flexible outer tissue covering the body of a vertebrate animal, with three main functions: protection, regulation, and sensation.[1]  Other animal coverings, such as the arthropod exoskeleton, have different developmental origin, structure and chemical composition. The adjective cutaneous means \"of the skin\" (from Latin cutis \\'skin\\'). In mammals, the skin is an organ of the integumentary system made up of multiple layers of ectodermal tissue and guards the underlying muscles, bones, ligaments, and internal organs. Skin of a different nature exists in amphibians, reptiles, and birds.[2] Skin (including cutaneous and subcutaneous tissues) plays crucial roles in formation, structure, and function of extraskeletal apparatus such as horns of bovids (e.g., cattle) and rhinos, cervids\\' antlers, giraffids\\' ossicones, armadillos\\' osteoderm, and os penis/os clitoris.[3]  All mammals have some hair on their skin, even marine mammals like whales, dolphins, and porpoises that appear to be hairless. The skin interfaces with the environment and is the first line of defense from external factors. For example, the skin plays a key role in protecting the body against pathogens[4] and excessive water loss.[5] Its other functions are insulation, temperature regulation, sensation, and the production of vitamin D folates.  Severely damaged skin may heal by forming scar tissue. This is sometimes discoloured and depigmented. The thickness of skin also varies from location to location on an organism. In humans, for example, the skin located under the eyes and around the eyelids is the thinnest skin on the body at 0.5\\xa0mm thick and is one of the first areas to show signs of aging such as \"crows feet\" and wrinkles. The skin on the palms and the soles of the feet is the thickest skin on the body as 4\\xa0mm thick. The speed and quality of wound healing in skin is promoted by the reception of estrogen.[6][7][8]  Fur is dense hair.[9] Primarily, fur augments the insulation the skin provides but can also serve as a secondary sexual characteristic or as camouflage. On some animals, the skin is very hard and thick and can be processed to create leather. Reptiles and most fish have hard protective scales on their skin for protection, and birds have hard feathers, all made of tough beta-keratins. Amphibian skin is not a strong barrier, especially regarding the passage of chemicals via skin, and is often subject to osmosis and diffusive forces. For example, a frog sitting in an anesthetic solution would be sedated quickly as the chemical diffuses through its skin. Amphibian skin plays key roles in everyday survival and their ability to exploit a wide range of habitats and ecological conditions.[10]  The word skin originally only referred to dressed and tanned animal hide and the usual word for human skin was hide. Skin is a borrowing from Old Norse skinn \"animal hide, fur\", ultimately from the Proto-Indo-European root *sek-, meaning \"to cut\" (probably a reference to the fact that in those times animal hide was commonly cut off to be used as garment).[11]    Mammalian skin is composed of two primary layers:  The epidermis is composed of the outermost layers of the skin. It forms a protective barrier over the body\\'s surface, responsible for keeping water in the body and preventing pathogens from entering, and is a stratified squamous epithelium,[12] composed of proliferating basal and differentiated suprabasal keratinocytes.  Keratinocytes are the major cells, constituting 95% of the epidermis,[12] while Merkel cells,  melanocytes and Langerhans cells are also present. The epidermis can be further subdivided into the following strata or layers (beginning with the outermost layer):[13]  Keratinocytes in the stratum basale proliferate through mitosis and the daughter cells move up the strata changing shape and composition as they undergo multiple stages of cell differentiation to eventually become anucleated. During that process, keratinocytes will become highly organized, forming cellular junctions (desmosomes) between each other and secreting keratin proteins and lipids which contribute to the formation of an extracellular matrix and provide mechanical strength to the skin.[14] Keratinocytes from the stratum corneum are eventually shed from the surface (desquamation).  The epidermis contains no blood vessels, and cells in the deepest layers are nourished by diffusion from blood capillaries extending to the upper layers of the dermis.  The epidermis and dermis are separated by a thin sheet of fibers called the basement membrane, which is made through the action of both tissues. The basement membrane controls the traffic of the cells and molecules between the dermis and epidermis but also serves, through the binding of a variety of cytokines and growth factors, as a reservoir for their controlled release during physiological remodeling or repair processes.[15]  The dermis is the layer of skin beneath the epidermis that consists of connective tissue and cushions the body from stress and strain. The dermis provides tensile strength and elasticity to the skin through an extracellular matrix composed of collagen fibrils, microfibrils, and elastic fibers, embedded in hyaluronan and proteoglycans.[14] Skin proteoglycans  are varied and have very specific locations.[16] For example, hyaluronan, versican and decorin are present throughout the dermis and epidermis extracellular matrix, whereas biglycan and perlecan are only found in the epidermis.  It harbors many mechanoreceptors (nerve endings) that provide the sense of touch and heat through nociceptors and thermoreceptors. It also contains the hair follicles, sweat glands, sebaceous glands, apocrine glands, lymphatic vessels and blood vessels. The blood vessels in the dermis provide nourishment and waste removal from its own cells as well as for the epidermis.  Dermis and subcutaneous tissues are thought to contain germinative cells involved in formation of horns, osteoderm, and other extra-skeletal apparatus in mammals.[3]  The dermis is tightly connected to the epidermis through a basement membrane and is structurally divided into two areas: a superficial area adjacent to the epidermis, called the papillary region, and a deep thicker area known as the reticular region.  The papillary region is composed of loose areolar connective tissue. This is named for its fingerlike projections called papillae that extend toward the epidermis. The papillae provide the dermis with a \"bumpy\" surface that interdigitates with the epidermis, strengthening the connection between the two layers of skin.  The reticular region lies deep in the papillary region and is usually much thicker. It is composed of dense irregular connective tissue and receives its name from the dense concentration of collagenous, elastic, and reticular fibers that weave throughout it. These protein fibers give the dermis its properties of strength, extensibility, and elasticity. Also located within the reticular region are the roots of the hair, sweat glands, sebaceous glands, receptors, nails, and blood vessels.  The subcutaneous tissue (also hypodermis)  is not part of the skin, and lies below the dermis. Its purpose is to attach the skin to underlying bone and muscle as well as supplying it with blood vessels and nerves. It consists of loose connective tissue and elastin. The main cell types are fibroblasts, macrophages and adipocytes (the subcutaneous tissue contains 50% of body fat). Fat serves as padding and insulation for the body.  Microorganisms like Staphylococcus epidermis colonize the skin surface. The density of skin flora depends on region of the skin. The disinfected skin surface gets recolonized from bacteria residing in the deeper areas of the hair follicle, gut and urogenital openings.  The epidermis of fish and of most amphibians consists entirely of live cells, with only minimal quantities of keratin in the cells of the superficial layer.[17] It is generally permeable, and in the case of many amphibians, may actually be a major respiratory organ.[18] The dermis of bony fish typically contains relatively little of the connective tissue found in tetrapods. [19] Instead, in most species, it is largely replaced by solid, protective bony scales.[20] Apart from some particularly large dermal bones that form parts of the skull, these scales are lost in tetrapods, although many reptiles do have scales of a different kind, as do pangolins.[21] Cartilaginous fish have numerous tooth-like denticles embedded in their skin, in place of true scales.[22]  Sweat glands and sebaceous glands are both unique to mammals, but other types of skin gland are found in other vertebrates.[23] Fish typically have a numerous individual mucus-secreting skin cells that aid in insulation and protection, but may also have poison glands, photophores, or cells that produce a more watery, serous fluid. In amphibians, the mucus cells are gathered together to form sac-like glands. Most living amphibians also possess granular glands in the skin, that secrete irritating or toxic compounds.[24]  Although melanin is found in the skin of many species, in the reptiles, the amphibians, and fish, the epidermis is often relatively colorless. Instead, the color of the skin is largely due to chromatophores in the dermis, which, in addition to melanin, may contain guanine or carotenoid pigments. Many species, such as chameleons and flounders may be able to change the color of their skin by adjusting the relative size of their chromatophores.[24]  Amphibians possess two types of glands, mucous and granular (serous). Both of these glands are part of the integument and thus considered cutaneous. Mucous and granular glands are both divided into three different sections which all connect to structure the gland as a whole. The three individual parts of the gland are the duct, the intercalary region, and lastly the alveolar gland (sac). Structurally, the duct is derived via keratinocytes and passes through to the surface of the epidermal or outer skin layer thus allowing external secretions of the body. The gland alveolus is a sac shaped structure that is found on the bottom or base region of the granular gland. The cells in this sac specialize in secretion. Between the alveolar gland and the duct is the intercalary system which can be summed up as a transitional region connecting the duct to the grand alveolar beneath the epidermal skin layer. In general, granular glands are larger in size than the mucous glands, however mucous glands hold a much greater majority in overall number.[25]  Granular glands can be identified as venomous and often differ in the type of toxin as well as the concentrations of secretions across various orders and species within the amphibians. They are located in clusters differing in concentration depending on amphibian taxa. The toxins can be fatal to most vertebrates or have no effect against others. These glands are alveolar meaning they structurally have little sacs in which venom is produced and held before it is secreted upon defensive behaviors.[25]  Structurally, the ducts of the granular gland initially maintain a cylindrical shape. However, when the ducts become mature and full of  fluid, the base of the ducts become swollen due to the pressure from the inside. This causes the epidermal layer to form a pit like opening on the surface of the duct in which the inner fluid will be secreted in an upwards fashion.[26]  The intercalary region of granular glands is more developed and mature in comparison with mucous glands. This region resides as a ring of cells surrounding the basal portion of the duct which are argued to have an ectodermal muscular nature due to their influence over the lumen (space inside the tube) of the duct with dilation and constriction functions during secretions. The cells are found radially around the duct and provide a distinct attachment site for muscle fibers around the gland\\'s body.[26]  The gland alveolus is a sac that is divided into three specific regions/layers. The outer layer or tunica fibrosa is composed of densely packed connective-tissue which connects with fibers from the spongy intermediate layer where elastic fibers, as well as nerves, reside. The nerves send signals to the muscles as well as the epithelial layers. Lastly, the epithelium or tunica propria encloses the gland.[26]  Mucous glands are non-venomous and offer a different functionality for amphibians than granular. Mucous glands cover the entire surface area of the amphibian body and specialize in keeping the body lubricated. There are many other functions of the mucous glands such as controlling the pH, thermoregulation, adhesive properties to the environment, anti-predator behaviors (slimy to the grasp), chemical communication, even anti-bacterial/viral properties for protection against pathogens.[25]  The ducts of the mucous gland appear as cylindrical vertical tubes that break through the epidermal layer to the surface of the skin. The cells lining the inside of the ducts are oriented with their longitudinal axis forming 90-degree angles surrounding the duct in a helical fashion.[26]  Intercalary cells react identically to those of granular glands but on a smaller scale. Among the amphibians, there are taxa which contain a modified intercalary region (depending on the function of the glands), yet the majority share the same structure.[26]  The alveolar or mucous glands are much more simple and only consist of an epithelium layer as well as connective tissue which forms a cover over the gland. This gland lacks a tunica propria and appears to have delicate and intricate fibers which pass over the gland\\'s muscle and epithelial layers.[26]  The epidermis of birds and reptiles is closer to that of mammals, with a layer of dead keratin-filled cells at the surface, to help reduce water loss. A similar pattern is also seen in some of the more terrestrial amphibians such as toads. However, in all of these animals there is no clear differentiation of the epidermis into distinct layers, as occurs in humans, with the change in cell type being relatively gradual. The mammalian epidermis always possesses at least a stratum germinativum and stratum corneum, but the other intermediate layers found in humans are not always distinguishable. Hair is a distinctive feature of mammalian skin, while feathers are (at least among living species) similarly unique to birds.[24]  Birds and reptiles have relatively few skin glands, although there may be a few structures for specific purposes, such as pheromone-secreting cells in some reptiles, or the uropygial gland of most birds.[24]  Cutaneous structures arise from the epidermis and include a variety of features such as hair, feathers, claws and nails. During embryogenesis, the epidermis splits into two layers: the periderm (which is lost) and the basal layer.  The basal layer is a stem cell layer and through asymmetrical divisions, becomes the source of skin cells throughout life. It is maintained as a stem cell layer through an autocrine signal, TGF alpha, and through paracrine signaling from FGF7 (keratinocyte growth factor) produced by the dermis below the basal cells. In mice, over-expression of these factors leads to an overproduction of granular cells and thick skin.[27][28]  Hair and feathers are formed in a regular pattern and it is believed to be the result of a reaction-diffusion system. This reaction-diffusion system combines an activator, Sonic hedgehog, with an inhibitor, BMP4 or BMP2, to form clusters of cells in a regular pattern. Sonic hedgehog-expressing epidermal cells induce the condensation of cells in the mesoderm. The clusters of mesodermal cells signal back to the epidermis to form the appropriate structure for that position. BMP signals from the epidermis inhibit the formation of placodes in nearby ectoderm.[citation needed]  It is believed that the mesoderm defines the pattern. The epidermis instructs the mesodermal cells to condense and then the mesoderm instructs the epidermis of what structure to make through a series of reciprocal inductions. Transplantation experiments involving frog and newt epidermis indicated that the mesodermal signals are conserved between species but the epidermal response is species-specific meaning that the mesoderm instructs the epidermis of its position and the epidermis uses this information to make a specific structure.[29]  Skin performs the following functions:  Skin is a soft tissue and exhibits key mechanical behaviors of these tissues.  The most pronounced feature is the J-curve stress strain response, in which a region of large strain and minimal stress exists and corresponds to the microstructural straightening and reorientation of collagen fibrils.[33] In some cases the intact skin is prestreched, like wetsuits around the diver\\'s body, and in other cases the intact skin is under compression. Small circular holes punched on the skin may widen or close into ellipses, or shrink and remain circular, depending on preexisting stresses.[34]  Tissue homeostasis generally declines with age, in part because stem/progenitor cells fail to self-renew or differentiate. Skin aging is caused in part by TGF-β by blocking the conversion of dermal fibroblasts into fat cells which provide support. Common changes in the skin as a result of aging range from wrinkles, discoloration, and skin laxity, but can manifest in more severe forms such as skin malignancies.[35][36] Moreover, these factors may be worsened by sun exposure in a process known as photoaging.[36] '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "wikitext = wikitext.replace(\"\\n\",\" \")\n",
        "wikitext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_6zwiViQh-n8",
        "outputId": "bd263587-ec04-4091-e9e2-96180cdcfcbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Skin is th'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "def get_wiki_text(word):\n",
        "  page = requests.get(\"https://en.wikipedia.org/wiki/%s\" % word)\n",
        "  soup = BeautifulSoup(page.text, 'html.parser')\n",
        "  wikitext = \" \".join([s.getText() for s in soup([\"p\"])])\n",
        "  return wikitext\n",
        "\n",
        "wiki_text = get_wiki_text(\"skin\")\n",
        "wiki_text[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "92T6xEMpduii",
        "outputId": "830d286f-08fe-4ddf-e3b9-845e68899baa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" is the J-curve stress strain response, in which a region of large strain and minimal stress exists and corresponds to the microstructural straightening and reorientation of collagen fibrils.[33] In some cases the intact skin is prestreched, like wetsuits around the diver's body, and in other cases the intact skin is under compression. Small circular holes punched on the skin may widen or close into ellipses, or shrink and remain circular, depending on preexisting stresses.[34]\\n Tissue homeostasis generally declines with age, in part because stem/progenitor cells fail to self-renew or differentiate. Skin aging is caused in part by TGF-β by blocking the conversion of dermal fibroblasts into fat cells which provide support. Common changes in the skin as a result of aging range from wrinkles, discoloration, and skin laxity, but can manifest in more severe forms such as skin malignancies.[35][36] Moreover, these factors may be worsened by sun exposure in a process known as photoaging.[36]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "wiki_text[-1000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Mh2RyPkRj1Nw"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import gutenberg,brown\n",
        "gutenwords = list(set([w.lower() for w in gutenberg.words()]))\n",
        "brownwords = list(set([w.lower() for w in brown.words()]))\n",
        "typical_words = gutenwords+brownwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t91D7g-niWE9",
        "outputId": "195da1da-d0de-4c44-c0d1-b59f95fde300"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cutaneous',\n",
              " 'amphibians',\n",
              " 'cutaneous',\n",
              " 'subcutaneous',\n",
              " 'amphibian',\n",
              " 'amphibian',\n",
              " 'basal',\n",
              " 'keratinocytes',\n",
              " 'keratinocytes',\n",
              " 'keratinocytes',\n",
              " 'keratin',\n",
              " 'extracellular',\n",
              " 'keratinocytes',\n",
              " 'dermis',\n",
              " 'dermis',\n",
              " 'dermis',\n",
              " 'dermis',\n",
              " 'dermis',\n",
              " 'extracellular',\n",
              " 'dermis']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "def get_words_from_wiki_text(wikitext,min_n=3):\n",
        "  words = toktag(wikitext)\n",
        "  possible_words = [token.lower() for token,tag in words if tag in [\"NN\",\"NNS\",\"JJ\"] and token.lower() not in typical_words]\n",
        "  possible_words = [w for w in possible_words if w.isalpha() and len(w)>=5]\n",
        "  possible_words_at_least_n = [w for w in possible_words if possible_words.count(w)>=min_n] ## at least\n",
        "  return possible_words_at_least_n\n",
        "\n",
        "get_words_from_wiki_text(wiki_text)[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PnwMJA0zkk1n"
      },
      "outputs": [],
      "source": [
        "def get_related_wikipedia_words(text):\n",
        "  words = toktag(text)\n",
        "  possible_words = list(set([token.lower() for token,tag in words if tag in [\"NN\",\"NNP\"] and token.isalpha()]))\n",
        "  random.shuffle(possible_words)\n",
        "  for pw in possible_words:\n",
        "    try:\n",
        "      relateds = get_words_from_wiki_text(get_wiki_text(pw))\n",
        "      if relateds!=[]:\n",
        "        return (pw,relateds)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "#get_related_wikipedia_words(\"The skin is king\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SfXz8sYymXBe",
        "outputId": "a34cbc2a-a0af-435d-b9c7-f7078903690e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This needs some specificity...when I see the word \"skin\" I think of \"cutaneous.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "def COMMENT_with_wikipedia(text):\n",
        "  word_and_relateds = get_related_wikipedia_words(text)\n",
        "  if word_and_relateds==None:\n",
        "    return\n",
        "  word,related_words = word_and_relateds\n",
        "  rw = random.choice(related_words)\n",
        "  pizzazz = ['pizzazz','oomph','cleverness','more interesting language','specificity']\n",
        "  return 'This needs some %s...when I see the word \"%s\" I think of \"%s.\"' % (random.choice(pizzazz),word,rw)\n",
        "\n",
        "\n",
        "COMMENT_with_wikipedia(\"the skin is a dog.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr6urdM6tv6s"
      },
      "source": [
        "**Comment on chunk:** Extract a syntactic chunk (phrase, clause, etc.) from input text and comment on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FmALSjOEecm-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "pip install benepar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9gzLq_P_8yL",
        "outputId": "8f03e85d-52c3-464d-b56d-d2a540d80c3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import benepar\n",
        "benepar.download('benepar_en3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FuZiALOaa24",
        "outputId": "f0f48ba5-1b12-4f5b-96a5-0b75f3eaa4a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<benepar.integrations.spacy_plugin.BeneparComponent at 0x7f4ea7da3640>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwtnQA81a24X",
        "outputId": "f2071584-f9a9-47bc-a9e2-32c7b3fcf2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/distributions/distribution.py:51: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[That old wallet picture,\n",
              " That,\n",
              " old,\n",
              " wallet,\n",
              " picture,\n",
              " is not in the really old house where I sleep,\n",
              " is,\n",
              " not,\n",
              " in the really old house where I sleep,\n",
              " .,\n",
              " That,\n",
              " old,\n",
              " wallet,\n",
              " picture,\n",
              " is,\n",
              " not,\n",
              " in the really old house where I sleep,\n",
              " in,\n",
              " the really old house where I sleep,\n",
              " in,\n",
              " the really old house where I sleep,\n",
              " the really old house,\n",
              " where I sleep,\n",
              " the really old house,\n",
              " the,\n",
              " really old,\n",
              " house,\n",
              " where I sleep,\n",
              " where,\n",
              " I sleep,\n",
              " the,\n",
              " really old,\n",
              " really,\n",
              " old,\n",
              " house,\n",
              " where,\n",
              " I sleep,\n",
              " I,\n",
              " sleep,\n",
              " really,\n",
              " old,\n",
              " I,\n",
              " sleep]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "def get_chunks_from_a_string(inputstring):\n",
        "  all_chunks = []\n",
        "  top_chunks = list(list(nlp(inputstring).sents)[0]._.children)\n",
        "  #all_chunks += top_chunks\n",
        "  stack = top_chunks\n",
        "  while True:\n",
        "    try:\n",
        "      current_string = stack.pop(0)\n",
        "      all_chunks.append(current_string)\n",
        "      chunks = list(current_string._.children)\n",
        "      if len(list(chunks))!=0:\n",
        "        all_chunks += chunks\n",
        "        stack += chunks\n",
        "    except:\n",
        "      return all_chunks\n",
        "\n",
        "\n",
        "list(get_chunks_from_a_string(\"That old wallet picture is not in the really old house where I sleep.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "n7jB_ngZl0sE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0l8LmHq7hgGl"
      },
      "outputs": [],
      "source": [
        "positives = [\"specific\",\"erudite\",\"clear\",\"crisp\",\\\n",
        "             \"noble\",\"modern\",\"colorful\",\"humane\",\\\n",
        "             \"connected\",\"tender\"]\n",
        "\n",
        "negatives = [\"over the top\",\"verbose\",\"'poetic'\",\"expected\",\"macho\",\"effete\"]\n",
        "\n",
        "topics = ['flowers','dirt',\"moisture\",\"kind of classical allusion\",\"toxic energy\",\"alliteration\",\"rhythm\"]\n",
        "topics_JJ = [\"reflective of \"+i for i in [\"our political situation\",\"the climate catastrophe\",\"globalization\",\"our digitalial millieu\"]]\n",
        "concepts = ['truth','religion','gender','economics','communism','markets','futurity','evil','organization','chaos','technology','consciousness','embodiment','salvation','prayer']\n",
        "topics_JJ += [\"reflective of the %s between %s and %s\" % (random.choice(['link','tension']),a,b) for a,b in list(itertools.permutations(concepts,2))]\n",
        "\n",
        "simple_chunk_recommendations = [\n",
        "                                \"'<targetChunk>'...don't you think this is a little too <negative>?\",\n",
        "                                \"'<targetChunk>'...I just wish this could be a little more <topicJJ>\",\n",
        "                                \"'<targetChunk>'...I just feel like this needs some <topic>?\",\n",
        "                                \"'<targetChunk>'---this is the soul of the line.  (Everything else...I don't love?)\",\n",
        "                                \"'<targetChunk>'---I'd try something else here.\",\n",
        "                                \"'<targetChunk>'---yes, I want this but more so---dial it up!\"\n",
        "                                ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0hkwhqYc10d3",
        "outputId": "652aaa39-68c9-4f84-fcd5-c3b201d77498"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'is no hope'...don't you think this is a little too expected?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "def generate_simple_chunk_rec():\n",
        "  tag2options = {\"topic\":topics,\"negative\":negatives,\"topicJJ\":topics_JJ}\n",
        "  template = random.choice(simple_chunk_recommendations)\n",
        "  to_replace = [t for t in re.findall(r'(?:<)([A-Za-z]{1,})(?:>)',template) if t.startswith('target')==False]\n",
        "  for tag in to_replace:\n",
        "    template = template.replace(\"<\"+tag+\">\",random.choice(tag2options[tag]),1)\n",
        "  return template\n",
        "\n",
        "def COMMENT_chunk_recommendation(text):\n",
        "  all_chunks = get_chunks_from_a_string(text)\n",
        "  ok_chunks = [c for c in all_chunks if len(c)>2 and len(c)<9]\n",
        "  if len(ok_chunks)<1:\n",
        "    return\n",
        "  chunk = random.choice(ok_chunks).text\n",
        "  template = generate_simple_chunk_rec()\n",
        "  template = template.replace(\"<targetChunk>\",chunk)\n",
        "  return template\n",
        "  \n",
        "COMMENT_chunk_recommendation(\"I like you very much, but under the swollen forest there is no hope\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlI8kS1tCahM"
      },
      "source": [
        "**Ban Topics**: Forbid topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kHFsmUfavSuP"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "pwar-Be9vbCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee71a3f9-ed56-4076-eb88-5027d3b23e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.0% 65.3/66.0MB downloaded"
          ]
        }
      ],
      "source": [
        "vector_model = api.load(\"glove-wiki-gigaword-50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hi68_YHxvzw3"
      },
      "outputs": [],
      "source": [
        "topic_words = {\n",
        "    \"nature\":[\"rock\",\"tree\",\"flower\",\"dirt\",\"sun\",\"sky\",\"stone\",\"soil\",\"grass\",\"moss\"],\n",
        "    \"animal\":[\"wolf\",\"spider\",\"hamster\",\"cat\",\"dog\",\"hyena\",\"rat\",\"lion\",\"bear\",\"koala\",\"snake\",\"bug\",\"deer\"],\n",
        "    \"bird\":[\"bird\",\"penguin\",\"owl\",\"nest\",\"egg\",\"beak\",\"feather\",\"raven\",\"flight\",\"roost\"],\n",
        "    \"celestial\":[\"moon\",\"sky\",\"sun\",\"planet\",\"constellation\",\"star\",\"pisces\",\"capricorn\",\"zodiac\"],\n",
        "    \"digital\":[\"computer\",\"twitter\",\"facebook\",\"phone\",\"iphone\",\"app\",\"hacker\",\"algorithm\",\"code\"],\n",
        "    \"religion\":[\"angel\",\"god\",\"pray\",\"prayer\",\"salvation\",\"sin\",\"saint\",\"forgiveness\",\"fasting\",\"resurrection\",\"liturgy\",\"grace\"],\n",
        "    \"school\":[\"university\",\"college\",\"exam\",\"quiz\",\"student\",\"study\",\"degree\"],\n",
        "    \"violent\":[\"sword\",\"gun\",\"missile\",\"knife\",\"kick\",\"punch\",\"blood\",\"break\",\"cut\",\"die\",\"laceration\",\"injury\"],\n",
        "    \"kinfolk\":[\"father\",\"brother\",\"mother\",\"cousin\",\"family\"],\n",
        "    \"political\":[\"communism\",\"democracy\",\"government\",\"vote\",\"election\",\"coup\",\"anarchy\",\"fascism\",\"leader\",\"president\",\"senator\"],\n",
        "    \"body\":[\"spit\",\"shit\",\"fart\",\"vomit\",\"bone\",\"heart\",\"lung\",\"tongue\",\"lymph\",\"blood\",\"joint\"],\n",
        "    \"war\":[\"bombing\",\"invastion\",\"incursion\",\"army\",\"soldier\",\"casualty\",\"tank\",\"artillery\"],\n",
        "    \"ocean\":[\"seaweed\",\"whale\",\"ocean\",\"brine\",\"deepwater\",\"atlantic\",\"pacific\",\"sea\",\"turtle\",\"wave\",\"tide\"],\n",
        "    \"industrial\":[\"factory\",\"machine\",\"forge\",\"electricity\",\"gear\",\"dynamo\",\"steel\",\"coal\",\"mill\",\"product\",\"industrialization\",\"sweatshop\"],\n",
        "    \"finance\":[\"trade\",\"market\",\"dollar\",\"bank\",\"investment\",\"finance\",\"capitalism\",\"cash\",\"gold\",\"silver\"],\n",
        "    \"science\":[\"experiment\",\"element\",\"chemical\",\"microscope\",\"scientist\",\"observatory\",\"research\",\"physics\",\"oxygen\",\"helium\",\"hydrogen\",\"isotope\",\"atomic\",],\n",
        "    \"writing\":[\"pen\",\"pencil\",\"paper\",\"book\",\"poem\",\"essay\",\"literature\"],\n",
        "    \"darkness\":[\"dark\",\"night\",\"dusk\",\"midnight\",\"moon\",\"gloaming\"],\n",
        "    \"lustrous\":[\"light\",\"shine\",\"brightness\",\"beam\",\"sun\",\"dawn\"],\n",
        "    \"sport\":[\"sport\",\"racquet\",\"ball\",\"baseball\",\"football\",\"tennis\",\"basketball\",\"throw\",\"catch\"],\n",
        "    \"romance\":[\"romance\",\"beloved\",\"adore\",\"love\",\"passion\",\"sex\",\"kiss\",\"yearning\"],\n",
        "    \"death\":[\"dead\",\"death\",\"buried\",\"funeral\",\"demise\",\"forgotten\",\"grave\",\"dying\"],\n",
        "    \"face\":[\"face\",\"eye\",\"mouth\",\"expression\",\"nose\",\"smle\",\"lips\",\"forehead\",\"frown\"],\n",
        "    \"shopping\":[\"shopping\",\"purchase\",\"deal\",\"catalogue\",\"sale\",\"dollar\",\"shop\",\"mall\"],\n",
        "    \"season\":[\"season\",\"winter\",\"summer\",\"spring\",\"autumn\"],\n",
        "    \"music\":[\"music\",\"song\",\"orchestra\",\"singer\",\"melody\",\"tune\",\"ballad\",\"concerto\",\"violin\",\"guitar\",\"piano\"],\n",
        "    \"law\":[\"law\",\"criminal\",\"conviction\",\"court\",\"judge\",\"tribunal\",\"tort\",\"constitution\",\"prisoner\"],\n",
        "    \"urban\":[\"skyscraper\",\"city\",\"urban\",\"subway\",\"taxi\",\"crowd\",\"café\",\"flaneur\"],\n",
        "    \"food\":[\"food\",\"eat\",\"taste\",\"snack\",\"lunch\",\"dinner\",\"delicious\",\"meal\",\"meat\",\"sushi\",\"pasta\",\"bread\"],\n",
        "    \"alcohol\":[\"wine\",\"beer\",\"alcohol\",\"drunk\",\"cocktail\",\"bourbon\",\"vodka\"],\n",
        "    \"furniture\":[\"chair\",\"table\",\"sofa\",\"clock\",\"drawer\"],\n",
        "    \"architectural\":[\"architecture\",\"roof\",\"blueprint\",\"building\",\"skyscraper\",\"door\",\"window\",\"mansion\",\"brownstone\"],\n",
        "    \"negative\":[\"sadness\",\"envy\",\"scream\",\"hate\",\"insomnia\",\"loss\",\"bereft\",\"emptiness\",\"frustration\",\"weep\"],\n",
        "}\n",
        "\n",
        "all_topics = topic_words.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU0Y4nkiEDQJ",
        "outputId": "1d8c2171-e76b-4d3a-9236-1360607e8d70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "all_topics = randrand(all_topics,min=round(len(all_topics)*.5)) ## sample\n",
        "len(all_topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T5D0IPHIwAI5",
        "outputId": "e0cd8484-8da6-45d6-d253-dc49d9cb89e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'architectural'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "def sim(w1,w2,model=vector_model):\n",
        "  \"\"\"\n",
        "  error handle list comprehension\n",
        "  \"\"\"\n",
        "  try:\n",
        "    return model.similarity(w1,w2)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "def test_word_against_topic_sets(word,topics=all_topics,thresh=0.67,top_n=4):\n",
        "  related_topic = None\n",
        "  related_score = -100\n",
        "  for topic in topics:\n",
        "    related_words = topic_words[topic]\n",
        "    scored = [s for s in [sim(word,rw) for rw in related_words] if s!=None] ## filter out nones from sim()\n",
        "    scored.sort(reverse=True)\n",
        "    if len(scored)>0: ## stop zero division error\n",
        "      top_avg = (sum(scored[:top_n])/len(scored[:top_n]))\n",
        "      if (top_avg>related_score) and (top_avg>thresh):\n",
        "        related_score = top_avg\n",
        "        related_topic = topic\n",
        "  return related_topic\n",
        "    \n",
        "test_word_against_topic_sets('house',topic_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DT5puI0iaQFR"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "n_topics_to_ban = random.randint(1,len(topic_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGvl6jSII9DK",
        "outputId": "cd803be6-cdc6-40d6-f335-0c3adc311aad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['industrial',\n",
              " 'body',\n",
              " 'face',\n",
              " 'religion',\n",
              " 'writing',\n",
              " 'finance',\n",
              " 'political',\n",
              " 'shopping',\n",
              " 'lustrous',\n",
              " 'darkness',\n",
              " 'music',\n",
              " 'romance',\n",
              " 'death',\n",
              " 'sport',\n",
              " 'school',\n",
              " 'furniture',\n",
              " 'kinfolk',\n",
              " 'nature',\n",
              " 'food',\n",
              " 'digital',\n",
              " 'negative',\n",
              " 'urban',\n",
              " 'violent',\n",
              " 'ocean',\n",
              " 'bird',\n",
              " 'celestial',\n",
              " 'architectural',\n",
              " 'war',\n",
              " 'science']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "banned = random.sample(topic_words.keys(),n_topics_to_ban)\n",
        "banned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "h03DU439TlHQ"
      },
      "outputs": [],
      "source": [
        "def COMMENT_test_against_banned_topics(text,banned_topics=banned):\n",
        "  pos_tagged = toktag(text)\n",
        "  nouns = [token.lower() for token,tag in pos_tagged if tag in [\"NN\",\"NNS\"]]\n",
        "  random.shuffle(nouns)\n",
        "  for n in nouns:\n",
        "    banned = test_word_against_topic_sets(n,topics=banned_topics)\n",
        "    if banned!=None:\n",
        "      hmm = random.choice(['hmm','ugh','really?'])\n",
        "      que = random.choice([\".\",'?',\", maybe?\",\", no?\",\"!\"])\n",
        "      dam = random.choice([\"damn \",\"tedious \",\"\",\"\",\"\",\"\"])\n",
        "      return '\"%s\"?...%s...enough of this %s%s stuff%s' % (n.capitalize(),hmm,dam,banned,que)\n",
        "      break\n",
        "\n",
        "COMMENT_test_against_banned_topics(\"I believe in the silver.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqel2jwvN9Yj"
      },
      "source": [
        "**Ban Letter**: Forbid the use of a letter that occurs in the input string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qTd07T3MUw5j",
        "outputId": "86fab676-c004-4c51-a849-8128243b462e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Try getting rid of all the \"i\"\\'s. There are entirely too many.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "def COMMENT_remove_letter(text):\n",
        "  try:\n",
        "    letter = random.choice([l for l in list(set([l for l in text if l.isalpha()])) if text.count(l)>3])\n",
        "    return 'Try getting rid of all the \"%s\"\\'s.%s' % (letter,random.choice([\" There are entirely too many.\",\"\"]))\n",
        "  except IndexError:\n",
        "    pass\n",
        "\n",
        "COMMENT_remove_letter(\"This is so deliciously small.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfUXDeo3qeTj"
      },
      "source": [
        "**Begins With:** Tells writer to replace a word with another word beginning with a specific letter with a specific number of syllables and possibly a source (e.g. Milton or Dickinson)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HNn7alYZfYAr"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stops = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "gWMl1PB7FRqW"
      },
      "outputs": [],
      "source": [
        "sources = [\"Milton\",\"Emily Dickinson\",\"an LL Bean catalogue\",\"a set of instructions\",\"an old architectural magazine from Japan\",\n",
        "             \"George Herbert\",\"a conversation with a dear one\",\"your private language\",\"how your friends used to talk\",\n",
        "             \"a family record\", \"a legal matter\",\"a secret internet\",\"the Bible\",\"the Apophthegmata\",\"the Baltimore Catechism\",\n",
        "             \"Speech and Language Processing 2nd Edition (Jurafsky & Martin)\",\"a witty conversation\",\"a psychoanalytic seminar\",\"an argument\"]\n",
        "sources+=random.sample([\"an old book about how a %s works\" % w for w in [\"company\",\"market\",\"body\",\"family\",\"capitalist economy\",\n",
        "                                                                           \"friendship\",\"thought\",\"mechanical watch\",\"confession\",\n",
        "                                                                          \"miracle\",\"city\",\"language\",\"computer\",\"syndicalist economy\",\n",
        "                                                                           \"prison\",\"superego\",\"mezzotint\",\"monastery\"]],3)\n",
        "  \n",
        "\n",
        "sources = randrand(sources,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8MSf1gSRUxyH",
        "outputId": "2d018057-9d55-4f68-cb5e-92b9d327ae4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What if you swapped \"name\" with a 4 syllable word that begins with \"h\" and that sounds like it could be from a witty conversation?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "def letter_comment(word):\n",
        "  alphabet = 'abcdefghijklmnopqrstuv'\n",
        "  letter = random.choice(alphabet.replace(word[0].lower(),\"\")) ## not already first letter\n",
        "  return 'with a word that begins with \"%s\"' % letter\n",
        "\n",
        "def syllable_comment(comment):\n",
        "  n = random.randint(1,6)\n",
        "  comment = comment.replace(\"with a word\",\"with a %d syllable word\" % n)\n",
        "  return comment\n",
        "\n",
        "def source_comment():\n",
        "  source = random.choice(sources)\n",
        "  leadup = random.choice(['sounds like it could be from','puts one in mind of','has the flavor of'])\n",
        "  return \"and that %s %s\" % (leadup,source)\n",
        "\n",
        "def comment_on_word(word):\n",
        "  comment = 'What if you swapped \"%s\"' % word\n",
        "  #if random.choice([True,True,True,True,False]):\n",
        "  comment+=\" \"+letter_comment(word)\n",
        "  if random.choice([True,False]):\n",
        "    comment = syllable_comment(comment)\n",
        "    if random.choice([True,False]):\n",
        "      comment+=\" \"+source_comment()\n",
        "  # else:\n",
        "  #   comment+=\" with a %s word\" % random.choice(['better','sweeter','greener','redder','bluer','indestructable','truer','more costly','holier'])\n",
        "  comment = comment+'?' ## add period\n",
        "  return comment\n",
        "\n",
        "def COMMENT_replace_word(text):\n",
        "  pos_tagged = toktag(text)\n",
        "  possibilities = [token for token,tag in pos_tagged if (tag[0] in \"NJV\" and token.lower() not in stops)]\n",
        "  if len(possibilities)<1:\n",
        "    return\n",
        "  to_comment_on = random.choice(possibilities)\n",
        "  return comment_on_word(to_comment_on)\n",
        "\n",
        "COMMENT_replace_word(\"so this is my name\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbIljMr3kYHO"
      },
      "source": [
        "**Flip:** Suggest alternate starting word from other words in sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FSIrH6GedgGg",
        "outputId": "e0c34f88-fd12-42b2-87d3-7526fe92630c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\'d move \"world\" to the beginning of the sentence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "def COMMENT_flip(text):\n",
        "  tokens = [w.lower() for w in tokenize.word_tokenize(text)]\n",
        "  possible_first_words = [w for w in tokens if w!=tokens[0] and w.isalpha() and w not in stops]\n",
        "  if len(possible_first_words)<1:\n",
        "    return\n",
        "  new_first_word = random.choice(possible_first_words)\n",
        "  return 'I\\'d move \"%s\" to the beginning of the sentence.' % new_first_word\n",
        "\n",
        "COMMENT_flip(\"The hill is not in the world.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8WYYCJ1kJzN"
      },
      "source": [
        "**Forbid Part of Speech**: Ban a part of speech that the input text contains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cUaK1JX-eZ2n",
        "outputId": "080e6a98-cfdb-4206-95ff-8172a76caec8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Try this again but without any verbs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "def COMMENT_ban_pos(text):\n",
        "  tag2pos = {\"JJ\":\"adjectives\",\"IN\":\"prepositions\",\"DT\":\"determiners (or 'articles') like 'an' or 'the' etc.\",\n",
        "             \"NN\":\"nouns\",\"NNS\":\"nouns\",\"RB\":\"adverbs\",\"NNP\":\"proper nouns\",\"NNPS\":\"proper nouns\",\n",
        "             \"VB\":\"verbs\",\"VBG\":\"gerunds or present participles\",\n",
        "           \"SYM\":'symbols (e.g. \"$\")',\n",
        "           \"VBN\":\"past participles\",\"VBZ\":\"present tense verbs\",\"VBD\":\"past tense verbs\",\"PRP\":\"pronouns\"}\n",
        "  ### only rarely forbid certain ones\n",
        "  if random.choice([True,True,True,True,False]):\n",
        "    del tag2pos[\"DT\"]\n",
        "  if random.choice([True,True,True,True,False]):\n",
        "    del tag2pos[\"NN\"]\n",
        "    del tag2pos[\"NNS\"]\n",
        "  if random.choice([True,True,False]):\n",
        "    del tag2pos[\"PRP\"]\n",
        "  tags = [tag for token,tag in toktag(text)]\n",
        "  tags_possible_to_ban = [t for t in tags if t in tag2pos]\n",
        "  if tags_possible_to_ban == []:\n",
        "    return ## none\n",
        "  tag_to_ban = random.choice(tags_possible_to_ban)\n",
        "  return \"Try this again but without any %s.\" % tag2pos[tag_to_ban]\n",
        "\n",
        "COMMENT_ban_pos(\"Running won't save water from falling.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXGaUNhHjyx-"
      },
      "source": [
        "**Proper Noun/Location:** Requests that a noun be changed to a proper noun with reference to a specific country, city, etc.. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tI3FlkBqrNeP",
        "outputId": "6154a697-407a-41bf-aaf4-73e8be5e8b5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Too vague. Make this a specific dog from French Canada.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "places = [\"Beijing\",\"Shenzen\",\"Brussels\",\"Brentwood\",\"Oakland\",\n",
        "          \"Carpathian Ruthenia\",\"upstate\",\"London\",\"Japan\",\"Mexico\", \"the Great Steppe\",\n",
        "          \"Argentina\",\"Uruguay\",\"New Jersey\",\"Northern California\",\n",
        "          \"Nashville\",\"Ancient Greece\",\"Ancient Rome\",\"the USSR\",\n",
        "          \"Nigeria\",\"Iraq\",\"Nepal\",\"France\",\"French Canada\",\"Finland\",\n",
        "          \"Russia\",\"Oslo\",\"middle America\",\"Byzantium\",\"Byzantium\",\"Illyria\",\"Christendom\"]\n",
        "\n",
        "places = randrand(places,min=5) ## sample\n",
        "\n",
        "def noun_to_proper_noun_request(noun):\n",
        "  place = random.choice(places)\n",
        "  return_string = \"Too vague. Make this a specific %s from %s.\" % (noun,place)\n",
        "  return return_string\n",
        "\n",
        "def COMMENT_solicit_proper_noun(text):\n",
        "  pos_tagged = toktag(text)\n",
        "  nn_s = [token.lower() for token,tag in pos_tagged if tag==\"NN\"]\n",
        "  #nns_s = [token for token,tag in pos_tagged if tag==\"NNS\"]\n",
        "  propers = [token for token,tag in pos_tagged if tag.startswith(\"NP\")]\n",
        "  if propers==[] and nn_s!=[]:\n",
        "    noun = random.choice(nn_s)\n",
        "    return noun_to_proper_noun_request(noun)\n",
        "\n",
        "COMMENT_solicit_proper_noun(\"You are my friend and my dog.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-1ebfDoiwUs"
      },
      "source": [
        "**Rhyme Suggestion:** Suggests that a word from input text rhyme or alliterate with another word from input text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sxlnloh4v82D",
        "outputId": "722dba13-0987-43cc-cfd9-078daec1e83e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Replace \"container\" with a similar word that is alliterative with \"soup.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "def COMMENT_suggest_rhyme(text):\n",
        "  pos_tagged = toktag(text)\n",
        "  possible_words = [token for token,tag in pos_tagged if tag in [\"NN\",\"NNS\",\"NNP\",\"NNPS\",\"JJ\"]]\n",
        "  if len(possible_words)<2:\n",
        "    return\n",
        "  w1,w2 = random.sample(possible_words,2)\n",
        "  if random.choice([True,True,False]):\n",
        "    if w1[-2:]!=w2[-2:]:  ## not a great way of detecting preexisting rhyme\n",
        "      return 'Replace \"%s\" with a similar word that rhymes with \"%s.\"' % (w1,w2)\n",
        "  else:\n",
        "    if w1[0]!=w2[0]: ## not a perfect way of detecting preexisting alliteration\n",
        "      return 'Replace \"%s\" with a similar word that is alliterative with \"%s.\"' % (w1,w2)\n",
        "\n",
        "COMMENT_suggest_rhyme(\"A star fell in my soup container\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMroM5WKijNg"
      },
      "source": [
        "**Prefixification:** Recommends a new version of a word with a prefix and/or suffix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pu_lKdPiyp23",
        "outputId": "695acbe8-cf48-4ad7-b77d-4ef3757713bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Instead of \"hand,\" what about \"bihand\"?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "prefixes = [\"hyper-\",\"hypo-\",\"un-\",\"extra-\",\"eigen\",\"iso\",\"thermo\",\"uni\",\"arche-\",\n",
        "            \"de-\",\"anti-\",\"pre-\",\"mega\",\"micro\",\"bio\",\"epi\",\"leio-\",\"geo\",\"gymno-\",\"gyro-\",\n",
        "            \"tele-\",\"e-\",\"post\",\"re\",\"centi-\",\"hecto-\",\"auto-\",\"dys\",\"counter-\",\n",
        "            \"ante\",\"ab\",\"bi\",\"co-\",\"exo-\",\"endo-\",\"ecto-\",\"mal\",\"multi-\",\"mono\",\"intra\",\"inter\",\"cyber-\",\n",
        "            \"pre\",\"i-\",\"Tex-\",\"Euro-\",\"pseudo-\",\"fore\",\"sub\",\"proto\",\"hemi\",\"x-\",\"xeno-\"\n",
        "            \"thermo-\",\"eco\",\"nimbo-\",\"aqua-\",\"cosmo-\",\"psycho-\",\"crypto-\",\"equi-\",\"ultra\",\"nocto-\",\n",
        "            \"neo-\",\"Russo-\",\"Sino-\",\"ur-\",\"Mc\",\"novo\",\"malo\",\"St.\",\"Fitz\",\"meso-\",\"ova\",\"zoa,\"\n",
        "            ]\n",
        "\n",
        "prefixes = list(set(prefixes))\n",
        "\n",
        "prefixes = randrand(prefixes,min=round(len(prefixes)*.8))\n",
        "\n",
        "suffixes = [\"ification\",\"istan\",\"burg\",\"berg\",\"ery\",\"ship\",\"osis\",\"ology\",\"ic\",\"ic\",\"ic\",\"ogen\",\"ivore\",\n",
        "            \"hood\",\"ism\",\"ant\",\"ful\",\"ectomy\",\" de guerre\",\"ite\",\"licious\",\"arium\",\"itis\",\"opathy\",\"otrope\",\n",
        "            \"ometry\",\"ous\",\"opoiesis\",\"ospasm\",\"oid\",\"osphere\",\"core\",\"ette\",\"-Con\",\"-gate\",\"fest\",\".com\",\".io\",\".ru\",\"-cel\"]\n",
        "\n",
        "suffixes = list(set(suffixes))\n",
        "\n",
        "suffixes = randrand(suffixes,min=round(len(suffixes)*.8))  \n",
        "\n",
        "def COMMENT_fix_a_word(text):\n",
        "  pos_tagged = toktag(text)\n",
        "  poss_words = [(token.lower(),tag) for token,tag in pos_tagged if (tag==\"NN\")]#or tag.startswith(\"V\") or tag.startswith(\"JJ\"))]\n",
        "  poss_words = [(token,tag) for token,tag in poss_words if token.lower() not in stops]\n",
        "  if poss_words==[]:\n",
        "    return ## no options\n",
        "  word,tag = random.choice(poss_words)\n",
        "  fixed = word\n",
        "  if random.choice([True,True,False]):\n",
        "    pre = random.choice(prefixes)\n",
        "    if fixed.startswith(pre)==False:\n",
        "      fixed = pre+fixed\n",
        "    if (random.choice([True,False,False,False]) and tag==\"NN\"):\n",
        "      suf = random.choice(suffixes)\n",
        "      if fixed.endswith(suf)==False:\n",
        "        fixed = fixed+suf\n",
        "  else:\n",
        "    if tag!=\"NN\":\n",
        "      return ## can't add suffix, return nothing\n",
        "    suf=random.choice(suffixes)\n",
        "    if fixed.endswith(suf)==False:\n",
        "      fixed = fixed+suf\n",
        "    if random.choice([True,False,False,False]):\n",
        "      pre = random.choice(prefixes)\n",
        "      if fixed.startswith(pre)==False:\n",
        "        fixed = pre+fixed\n",
        "  return 'Instead of \"%s,\" what about \"%s\"?' % (word,fixed) \n",
        "\n",
        "\n",
        "COMMENT_fix_a_word(\"Crown in hand, my old hat, I ran through THE STORE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLJF8k0Ytlf7"
      },
      "source": [
        "**Recommend Literary Device:** randomly suggest one or two literary devices, rhetorical figures, or other such things.\n",
        "\n",
        "(Fallback function: does not take input.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-okNssVBs4tw",
        "outputId": "da308316-8add-4857-cf56-dfbf0a6be21f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "## base figs, from some \"literary figures\" website and my own reckoning or maybe \"literary devices\"\n",
        "\n",
        "figures = [\"aphaeresis\",\"zeugma\",\"chiasmus\",\"foreign word\",\"number\",\"asyndeton\",\"adynaton\",\"anacoluthon\",\n",
        "                   \"allusion\",\"antimetabole\",\"anadiplosis\",\"anthimeria\",\"catachresis\",\"circumlocution\",\"catalog\",\n",
        "                   \"chiasmus\",\"caesura\",\"cliché\",\"diacope\",\"dysphemism\",\"encomium\",\"elision\",\"ellipsis\",\n",
        "                   \"enthymeme\",\"enumeration\",\"internal rhyme\",\"kenning\",\"malapropism\",\"moral\",\"neologism\",\"oxymoron\",\"onomatopoeia\",\n",
        "           \"spoonersim\",\"palindrome\",\"pleonasm\",\"pun\",\"sibilance\",\"solecism\",\"swear word\",\"brand name\",\n",
        "]\n",
        "\n",
        "extra_figure_number = len(figures)//2\n",
        "\n",
        "## from silva rhetoricae \n",
        "byu_figs = [\"abating\", \"abbaser\", \"abecedarian\", \"abcisio\", \"ablatio\", \"abominatio\", \"abuse\", \"abusio\", \"abusion\", \"acoloutha\", \"accismus\", \"accumulatio\", \"accusatio adversa\", \"accusatio\", \"acervatio\", \"acrostic\", \"acyrologia\", \"acyron\", \"adage\", \"adagium\", \"addubitatio\", \"adhortatio\", \"adianoeta\", \"adjectio\", \"adjournment\", \"adjudicatio\", \"adjunct\", \"adjunctio\", \"admonitio\", \"adnexio\", \"adnominatio\", \"adynata\", \"adynaton\", \"aeschrologia\", \"aetiologia\", \"affirmatio\", \"affirmation\", \"aganactesis\", \"agnominatio\", \"agnomination\", \"aischrologia\", \"allegory\", \"alleotheta\", \"alliteration\", \"amar Airrisio\", \"ambiguitas\", \"ambiguous\", \"amphibologia\", \"ampliatio\", \"anacephalaeosis\", \"anacoenosis\", \"anacoloutha\", \"anacoluthon\", \"anadiplosis\", \"anamnesis\", \"anangeon\", \"anaphora\", \"anapodoton\", \"anastrophe\", \"anemographia\", \"anesis\", \"antanaclasis\", \"antanagoge\", \"antenantiosis\", \"anthimeria\", \"anthropopatheia\", \"anthypophora\", \"anticategoria\", \"anticipation\", \"antilogy\", \"antimetabole\", \"antimetathesis\", \"antipersonification\", \"antiphrasis\", \"antiprosopopoeia\", \"antiptosis\", \"antirrhesis\", \"antisagoge\", \"antistasis\", \"antisthecon\", \"antistrophe\", \"antithesis\", \"antitheton\", \"antonomasia\", \"apagoresis\", \"aphaeresis\", \"aphorismus\", \"apocarteresis\", \"apocope\", \"apodioxis\", \"apodixis\", \"apologue\", \"apophasis\", \"apoplanesis\", \"aporia\", \"aposiopesis\", \"apostrophe\", \"apothegm\", \"apparent refusal\", \"appositio\", \"apposition\", \"ara\", \"articulus\", \"aschematismus\", \"aschematiston\", \"asphalia\", \"assonance\", \"assumptio\", \"assumption\", \"asteismus\", \"astrothesia\", \"asyndeton\", \"auxesis\", \"aversio\", \"barbarism\", \"battologia\", \"bdelygmia\", \"benedictio\", \"bomphiologia\", \"brachiepia\", \"brachylogia\", \"cacemphaton\", \"cacophonia\", \"cacosyntheton\", \"cacozelia\", \"casus pro casu\", \"catachresis\", \"catacosmesis\", \"cataphasis\", \"cataplexis\", \"categoria\", \"characterismus\", \"charientismus\", \"chiasmus\", \"chorographia\", \"chreia\", \"chronographia\", \"circumlocutio\", \"civille jest\", \"clause\", \"climax\", \"coenotes\", \"colon\", \"combined repetition\", \"comma\", \"common cause\", \"commoratio\", \"communicatio\", \"commutatio\", \"comparatio\", \"compensatio\", \"complexio\", \"compositum ex contrariis\", \"comprobatio\", \"conceit\", \"concessio\", \"conciliatio\", \"conclusio\", \"condescensio\", \"condescension\", \"conduplicatio\", \"congeries\", \"conjunctio\", \"consonance\", \"contencion\", \"contentio\", \"continued metaphor\", \"contractio\", \"contrarium\", \"contrast\", \"conversio\", \"correctio\", \"counterfait in personation\", \"counterfait place\", \"counter turne\", \"deesis\", \"dehortatio\", \"dendrographia\", \"deprecatio\", \"descriptio\", \"diacope\", \"diaeresis\", \"dialogismus\", \"dialysis\", \"dialyton\", \"dianoea\", \"diaphora\", \"diaporesis\", \"diaskeue\", \"diastole\", \"diasyrmus\", \"diazeugma\", \"dicaeologia\", \"digressio\", \"dilemma\", \"dirimens copulatio\", \"distinctio\", \"distributio\", \"ecphonesis\", \"ecphrasis\", \"ecthlipsis\", \"effictio\", \"elenchus\", \"ellipsis\", \"emphasis\", \"enallage\", \"enantiosis\", \"enargia\", \"encomium\", \"energia\", \"enigma\", \"ennoia\", \"enthymeme\", \"enumeratio\", \"epanalepsis\", \"epanodos\", \"epanorthosis\", \"epenthesis\", \"epergesis\", \"epexegesis\", \"epicrisis\", \"epilogus\", \"epimone\", \"epiphonema\", \"epiplexis\", \"epistrophe\", \"epitasis\", \"epitheton\", \"episynaloephe\", \"epitrochasmus\", \"epitrope\", \"epizeugma\", \"epizeuxis\", \"erotema\", \"ethopoeia\", \"eucharistia\", \"euche\", \"eulogia\", \"euphemismus\", \"eustathia\", \"eutrepismus\", \"example\", \"excitatio\", \"exclamatio\", \"excursus\", \"exergasia\", \"exouthenismos\", \"expeditio\", \"expolitio\", \"exuscitatio\", \"frequentatio\", \"geographia\", \"gnome\", \"graecismus\", \"hendiadys\", \"heterogenium\", \"homiologia\", \"homoeoprophoron\", \"homoeosis\", \"homoioptoton\", \"homoioteleuton\", \"horismus\", \"hydrographia\", \"hypallage\", \"hyperbaton\", \"hyperbole\", \"hypophora\", \"hypotyposis\", \"hypozeugma\", \"hypozeuxis\", \"hysterologia\", \"hysteron proteron\", \"icon\", \"indignatio\", \"inopinaturm\", \"insinuatio\", \"interrogatio\", \"inter se pugnantia\", \"intimation\", \"irony\", \"isocolon\", \"litotes\", \"macrologia\", \"martyria\", \"maxim\", \"medela\", \"meiosis\", \"membrum\", \"mempsis\", \"merismus\", \"mesarchia\", \"mesodiplosis\", \"mesozeugma\", \"metabasis\", \"metalepsis\", \"metallage\", \"metaphor\", \"metaplasm\", \"metastasis\", \"metathesis\", \"metonymy\", \"mimesis\", \"mycterismus\", \"noema\", \"oeonismus\", \"ominatio\", \"onedismus\", \"onomatopoeia\", \"optatio\", \"orcos\", \"oxymoron\", \"paenismus\", \"palilogia\", \"parabola\", \"paradiastole\", \"paradiegesis\", \"paradigma\", \"paradox\", \"paraenesis\", \"paragoge\", \"paralipsis\", \"parallelism\", \"paramythia\", \"parathesis\", \"parecbasis\", \"paregmenon\", \"parelcon\", \"parembole\", \"parenthesis\", \"pareuresis\", \"paroemia\", \"paroemion\", \"paromoiosis\", \"paromologia\", \"paronomasia\", \"parrhesia\", \"pathopoeia\", \"perclusio\", \"periergia\", \"period\", \"periphrasis\", \"perissologia\", \"peristasis\", \"permutatio\", \"personification\", \"philophronesis\", \"pleonasm\", \"ploce\", \"polyptoton\", \"polysyndeton\", \"pragmatographia\", \"procatalepsis\", \"proclees\", \"prodiorthosis\", \"proecthesis\", \"prolepsis\", \"prosapodosis\", \"proslepsis\", \"prosonomasia\", \"prosopographia\", \"prosopopoeia\", \"prosphonesis\", \"protherapeia\", \"prothesis\", \"protrope\", \"proverb\", \"prozeugma\", \"pysma\", \"ratiocinatio\", \"repetitio\", \"repotia\", \"restrictio\", \"rhetorical question\", \"sarcasmus\", \"scesis onomaton\", \"schematismus\", \"scheme\", \"scurra\", \"skotison\", \"sententia\", \"sermocinatio\", \"simile\", \"solecismus\", \"soraismus\", \"sorites\", \"subjectio\", \"sustentatio\", \"syllepsis\", \"syllogismus\", \"symperasma\", \"symploce\", \"synaeresis\", \"synaloepha\", \"synathroesmus\", \"syncatabasis\", \"syncategorema\", \"synchoresis\", \"synchysis\", \"syncope\", \"syncrisis\", \"synecdoche\", \"synoeciosis\", \"synonymia\", \"synthesis\", \"syntheton\", \"synzeugma\", \"systole\", \"systrophe\", \"tapinosis\", \"tasis\", \"tautologia\", \"taxis\", \"thaumasmus\", \"tmesis\", \"topographia\", \"topothesia\", \"traductio\", \"transitio\", \"transplacement\", \"tricolon\", \"verborum bombus\", \"zeugma\"]\n",
        "\n",
        "figures += random.sample(byu_figs,extra_figure_number)\n",
        "\n",
        "figures = list(set(figures))\n",
        "\n",
        "len(figures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0ecapC3E1Kw",
        "outputId": "c4bc71a4-55ba-4397-c913-b35b78f15218"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "figures = randrand(figures,min=3) ## sample\n",
        "len(figures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tNz3k3_HKpuP",
        "outputId": "162ea192-dc81-4864-878c-cf3979739aec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This really needs a chiasmus.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "import re\n",
        "def COMMENT_recommend_parts(inputtext=None): ## does nothing with argument, but accepts to keep like other functions\n",
        "  if random.choice([True,True,True,True,False]):\n",
        "    return_string = \"This really needs a %s.\" % random.choice(figures)\n",
        "  else:\n",
        "    return_string = \"This would be so much better if it had a %s and a %s.\" % tuple(random.sample(figures,2))\n",
        "  return_string = re.sub(r\" a ([aeiou])\",r\" an \\1\",return_string) ## a -> an\n",
        "  return return_string\n",
        "\n",
        "COMMENT_recommend_parts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjfzThmu-gpb"
      },
      "source": [
        "**Deconstructed Sestina:** One of several words, chosen from a larger list, is suggested as an ending word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PjJyMJOw_1VV"
      },
      "outputs": [],
      "source": [
        "words = [\"angel\",\"away\",\"force\",\"city\",\"fortune\",\"boat\",\"art\",\"center\",\"part\",\"earth\",\n",
        "         \"face\",\"praise\",\"fruit\",\"shade\",\"rest\",\"motion\",\"store\",\"need\",\"reply\",\n",
        "         \"grace\",\"nature\",\"thing\",\"order\",\"frame\",\"wood\",\"crown\",\"bread\",\"tomorrow\"] ### some from Herbert\n",
        "\n",
        "number_of_key_words = random.randrange(1,4)\n",
        "number_of_key_words = 2\n",
        "key_words = random.sample(list(set(words)),number_of_key_words)\n",
        "\n",
        "def COMMENT_suggest_key_word(inputtext=None):\n",
        "  \"\"\"\n",
        "  recommends in order\n",
        "  \"\"\"\n",
        "  word = key_words.pop(0)\n",
        "  key_words.append(word)\n",
        "  return 'Try ending with this word: \"%s.\"' % word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUyaDN4EAyp_",
        "outputId": "fb7e1029-3fdd-4a10-ca8b-19d5c295c356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Try ending with this word: \"away.\"\n",
            "Try ending with this word: \"rest.\"\n",
            "Try ending with this word: \"away.\"\n",
            "Try ending with this word: \"rest.\"\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "  print(COMMENT_suggest_key_word())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fstfZlFNUWUo"
      },
      "source": [
        "**Google Suggestion:** Suggests Googling a noun and another word and looking for inspiration in the results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "v3WeIg1qUjcz",
        "outputId": "b30fcf29-bc46-46d8-f8e7-417619dc43e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why don\\'t you try searching your notes or maybe your email for \"friend\" and \"1970s\"? Maybe you\\'ll find some inspiration.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "googlables = [\n",
        "    \"science\",\"1980s\",\"fin de siècle\",\"1970s\",\"Islam\",\"forbidden\",\"theory\",\"Kant\",\"Christ\",\"battle\",\"virtue\",\n",
        "    \"fragrance\",\"fabric\",\"house music\",\"downtown scene\",\"the Met\",\"tennis\",\"baseball\",\"automotive\",\"industrial\",\"economic\",\n",
        "    \"Nokia\",\"misprision\",\"civil\",\"trad\",\"Brentwood, Tennessee\",\"trivium\",\"McKinsey\",\"Chrysostom\",\"Ashbery\",\"George Herbert\",\"Eno\",\"Princeton\",\"Carpathia\"\n",
        "]\n",
        "\n",
        "def COMMENT_google_suggestion(text):\n",
        "  pos_tagged = toktag(text)\n",
        "  poss_words = [token.lower() for token,tag in pos_tagged if (tag in [\"NN\",\"NNS\"])]\n",
        "  if poss_words==[]:\n",
        "    return None\n",
        "  else:\n",
        "    a_noun = random.choice(poss_words)\n",
        "    a_googlable = random.choice(googlables)\n",
        "    return_string = \"\"\n",
        "    if random.choice([True,False,False]):\n",
        "      insult_word = random.choice(['uninspired','dull','expected','too familiar'])\n",
        "      return_string+='A little %s, to be frank. ' % insult_word\n",
        "    if random.choice([True,False,False,False]):\n",
        "      return_string+='You need to get outside your own head. '\n",
        "    if random.choice([True,True,True,False]):\n",
        "      searchtype = \"googling\"\n",
        "    elif random.choice([True,True,False]):\n",
        "      searchtype = \"twitter searching\"\n",
        "    else:\n",
        "      searchtype = \"searching your notes or maybe your email for\"\n",
        "    return_string+='Why don\\'t you try %s \"%s\" and \"%s\"?' % (searchtype,a_noun,a_googlable)\n",
        "    if random.choice([True,False]):\n",
        "      return_string+=' Maybe you\\'ll find some inspiration.'\n",
        "    return return_string\n",
        "\n",
        "COMMENT_google_suggestion(\"You are a good friend to me.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5E5Lo4a8SPy"
      },
      "source": [
        "**Add Grammatical Moves:** Suggests adding grammatical features (e.g. future tense), testing to make sure input text doesn't already have them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Zgbao3AV8sHE"
      },
      "outputs": [],
      "source": [
        "def future_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'going~VBG to~TO', \n",
        "      r'will~MD',\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return \"I think this line could be shifted into the future tense.\"\n",
        "\n",
        "def future_conditional_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'will~MD have~',\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return \"Maybe you could use the future tense.\"\n",
        "\n",
        "def conditional_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'\\w+ould~md'\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return 'Maybe you could use a word like \"could\" or \"should\" to entertain possibilities.'\n",
        "\n",
        "def past_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'\\w+~VBD',\n",
        "      r'\\w+~VBN'\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return 'Try switching this into past tense.'\n",
        "\n",
        "def proper_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'\\w+~NNPS?',\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return 'Maybe a proper noun?'\n",
        "\n",
        "def personal_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'i+~PRP',\n",
        "      r'me+~PRP',\n",
        "      r'mine+~PRP',\n",
        "      r'my+~PRP',\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return 'Why don\\'t you make this a bit more personal, in the first person?'\n",
        "\n",
        "\n",
        "def proper_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'\\w+~NNPS?',\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return 'Maybe a proper noun?'\n",
        "\n",
        "\n",
        "def preposition_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'\\w+~IN',\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return 'I\\'d love a prepositional phrase.'\n",
        "\n",
        "\n",
        "def number_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'\\w+~CD',\n",
        "      r'\\d',\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return 'This is a little fuzzy.  It needs a number to make things more precise.'\n",
        "\n",
        "\n",
        "def comp_super_adj_test(pos_tag):\n",
        "  regexes = [\n",
        "      r'\\w+~JJR',\n",
        "      r'\\w+~JJS',\n",
        "  ]\n",
        "  pos_tagged_as_string = \" \".join([token.lower()+\"~\"+tag for token,tag in pos_tag])\n",
        "  for reg in regexes:\n",
        "    if re.search(reg,pos_tagged_as_string)!=None:\n",
        "      return None\n",
        "  return random.choice(['What if you included a superlative or comparative adjective? That would make things more intense, wouldn\\'t they.',\"What if you included a superlative or comparative adjective?\"])\n",
        "\n",
        "\n",
        "tests = [\n",
        "    future_test,\n",
        "    conditional_test,\n",
        "    past_test,\n",
        "    proper_test,\n",
        "    preposition_test,\n",
        "    number_test,\n",
        "    comp_super_adj_test,\n",
        "    personal_test,\n",
        "]\n",
        "\n",
        "some_tests = randrand(tests,min=2)\n",
        "\n",
        "def COMMENT_on_grammar_not_used(text,tests=some_tests):\n",
        "  pos_tagged = toktag(text)\n",
        "\n",
        "  random.shuffle(tests)\n",
        "  for t in tests:\n",
        "    result = t(pos_tagged)\n",
        "    if result!=None:\n",
        "      #print(result)\n",
        "      return result\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B_AI_H_F_Wwr",
        "outputId": "ab09c7c2-2779-4db5-d196-9b51e7b4c025"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a little fuzzy.  It needs a number to make things more precise.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "COMMENT_on_grammar_not_used(\"I laugh.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA0TYOwTK1sh"
      },
      "source": [
        "**Line Length:** calls for different line length. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FZMl4bzrLKyn"
      },
      "outputs": [],
      "source": [
        "def COMMENT_on_line_length(text):\n",
        "  tokens = [tok for tok,tag in toktag(text)]\n",
        "  ## don't count punctuation\n",
        "  tokens = [tok for tok in tokens if any(c.isalpha() for c in tok)]\n",
        "  length = len(tokens)\n",
        "  possible_delta = round(length * .5)\n",
        "  delta = random.randrange(1,possible_delta)\n",
        "  if random.random()<.75:\n",
        "    delta = delta*-1 ## neg\n",
        "  goal_length = max(5,length+delta) ## set a minimum length\n",
        "  return \"This is %d words long, but I think the perfect number of words would be...%d.\" % (length,goal_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hRrxtHkhMcSk",
        "outputId": "255299d6-d414-40de-d135-4cab162de8bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is 7 words long, but I think the perfect number of words would be...5.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "COMMENT_on_line_length(\"you aren't---my friend's---dad Mr. Jeff.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAt8-3J7QMmZ"
      },
      "source": [
        "**Purposes of Poetry:** Reminds reader of the point of poetry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "geYygUSNRFUS"
      },
      "outputs": [],
      "source": [
        "purposes = [\n",
        " \"\\\"is not heard but overheard\\\"\",\n",
        " \"is \\\"the best words in the best order\\\"\",\n",
        " \"is \\\"the spontaneous overflow of powerful feelings\\\"\",\n",
        " \"\\\"must resist the intelligence almost successfully\\\"\",\n",
        " \"\\\"should mean what it says, literally and in every sense\\\"\",\n",
        " \"\\\"comes right with a click like a closing box\\\"\",\n",
        " \"\\\"gains a maximum of convincing power at the very moment that it abdicates any claim to truth\\\"\",\n",
        " \"\\\"is a momentary stay against confusion\\\"\",\n",
        " \"\\\"is ontology\\\"\",\n",
        " \"\\\"should be palpable and mute / as a globed fruit\\\"\",\n",
        " \"\\\"should feel physically as if the top of one's head were taken off\\\"\",\n",
        " \"\\\"tells the truth but tell it slant\\\"\",\n",
        " \"\\\"is not the sterile word play that, too often, the white fathers distorted the word poetry to mean\\\"\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y57aev3ySV86",
        "outputId": "b7b88d6e-0164-444c-b04c-05f0ab237a1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"is ontology\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "purpose_of_poetry = random.choice(purposes)\n",
        "#purpose_of_poetry = purposes[-1]\n",
        "\n",
        "purpose_of_poetry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ve0hBBa5VwS_"
      },
      "outputs": [],
      "source": [
        "def purpose_generator(purpose):\n",
        "  for i in range(9):\n",
        "    if i==0:\n",
        "      resp =  \"Just so you know, poetry %s.\" % purpose\n",
        "      yield resp.replace('\".','.\"').replace('poetry \"is ont','\"poetry is ont')\n",
        "    elif i==1:\n",
        "      yield \"Once again, bear in mind that poetry %s.\" % purpose.replace('\"',\"\")\n",
        "    elif i<5: \n",
        "      resp = \"I still feel like you could do more to make sure that this poem %s.\" % purpose.replace('\"',\"\")\n",
        "      resp = resp.replace('should be','is',1).replace('should feel','feels',1).replace('should mean','means',1).replace('must resist','resists',1)\n",
        "      yield resp\n",
        "    elif i<8:\n",
        "      resp = \"What is wrong with you? Don't you get that poetry %s?\" % purpose.replace('\"',\"\")\n",
        "      resp = resp.replace(\"poetry is\",\"poetry should be\",1).replace(\"poetry should be not\",\"poetry should not be\").replace(\"poetry tells\",\"poetry should tell\")\n",
        "      yield resp\n",
        "    else:\n",
        "      yield random.choice([\"I give up.\",\"...\",\"Oh well, I tried.\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "42mgkc1BZ0Ho"
      },
      "outputs": [],
      "source": [
        "pg = purpose_generator(purpose_of_poetry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "XCW2_fBMaSB2"
      },
      "outputs": [],
      "source": [
        "def COMMENT_purpose_of_poetry(inputtext=None):\n",
        "  try:\n",
        "    return next(pg)\n",
        "  except StopIteration:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX_LtWYdarxF",
        "outputId": "49102580-35c6-4bfc-d7f6-e5e10f166373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Just so you know, \"poetry is ontology.\"\n",
            "Once again, bear in mind that poetry is ontology.\n",
            "I still feel like you could do more to make sure that this poem is ontology.\n",
            "I still feel like you could do more to make sure that this poem is ontology.\n",
            "I still feel like you could do more to make sure that this poem is ontology.\n",
            "What is wrong with you? Don't you get that poetry should be ontology?\n",
            "What is wrong with you? Don't you get that poetry should be ontology?\n",
            "What is wrong with you? Don't you get that poetry should be ontology?\n",
            "I give up.\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  print(COMMENT_purpose_of_poetry())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "F_NDciXuFoGs"
      },
      "outputs": [],
      "source": [
        "COMMENT_purpose_of_poetry(\"this is null\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "wDjKKrJlHL7t"
      },
      "outputs": [],
      "source": [
        "pg = purpose_generator(purpose_of_poetry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szQmhFUW2gTi"
      },
      "source": [
        "**Extend line:** Offer continuation based on last part-of-speech of input "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "SBhzcSk634Z4"
      },
      "outputs": [],
      "source": [
        "tag2next_word = {\n",
        "    \"PRP\":[\"who\",\"who shall\",\"who did\",\"who never\",\"by whom\",\"who could\"],\n",
        "    \"VBG\":[\"in\",\"in\",\"up\",\"up\",\"with\",\"without\",\"for\",\"beyond\",\"but not\"],\n",
        "    \"VBD\":[\"up\",\"so that\",\"so very\"],\n",
        "    \"NN\":[\"that\",\"that will\",\", the kind\",\"named\",\"made of\",\"with its\"],\n",
        "    \"NNS\":[\"that\",\"that together\",\", all of them so\",\"most of them\",\"of\",\", which now I describe:\",\", which now I name:\"],\n",
        "    \"JJ\":[\"as the\",\"as one\",\"as those\",\", if not exactly\",\", a property yielded by\"],\n",
        "    \"NNP\":[\", a type of\",\", the only\",\"of\",]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "2_VajZgC4dJf"
      },
      "outputs": [],
      "source": [
        "def extend_line(inputtext,extension):\n",
        "  ending_part = re.findall(r\"(?:\\b\\w+\\b ?){3,4}$\",inputtext)\n",
        "  if ending_part==[]:\n",
        "    return None\n",
        "  else:\n",
        "    ending_part = ending_part[0]\n",
        "  output =  \"Yes! Keep going: \\\"...%s %s...\\\"\" % (ending_part,extension)\n",
        "  output = output.replace(\" ,\",\",\")\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "szD2HTU62vdw"
      },
      "outputs": [],
      "source": [
        "def COMMENT_extend_line(inputtext):\n",
        "  inputtext = inputtext.rstrip(\".,?\\\"!\")\n",
        "  pos_tagged = toktag(inputtext)\n",
        " #print(pos_tagged)\n",
        "  # while pos_tagged[-1][1][0].isalpha()==False: ## while last token is punctuation\n",
        "  #   pos_tagged.pop()\n",
        "  last_pos = pos_tagged[-1][1]\n",
        "  if last_pos not in tag2next_word:\n",
        "    return None\n",
        "  extension = random.choice(tag2next_word[last_pos])\n",
        "  return extend_line(inputtext,extension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sOKgk_zu2XEK",
        "outputId": "0bb74ff8-af52-4367-cc7a-dd0ee9478924"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes! Keep going: \"...unless it be perfect, a property yielded by...\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "COMMENT_extend_line(\"Take no light unless it be perfect.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOT2z5rA7b6z"
      },
      "source": [
        "**Push Toward Common Words:** Find a word that is rare and suggest the writer supply a plain, common alternative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "NISyDyVS7o0h"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import brown,gutenberg\n",
        "from nltk import FreqDist\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ke7bXcl17-73"
      },
      "outputs": [],
      "source": [
        "gutenwords_all = [w.lower() for w in gutenberg.words()]\n",
        "brownwords_all = [w.lower() for w in brown.words()]\n",
        "brown_gut_freqdist = FreqDist(gutenwords_all+brownwords_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLlFZChz7r0I",
        "outputId": "bb1d2556-56a4-4ab6-d5a8-d959cfcb2012"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "brown_gut_freqdist[\"dog\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQfG0ovP8oic",
        "outputId": "19f60420-cc9a-40e2-ed14-438ea6d5d1f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "min_count_of_word = random.randrange(1,4) ## 1 2 or 3\n",
        "min_count_of_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ziGdT6_B9fIC"
      },
      "outputs": [],
      "source": [
        "def get_count(token,the_fd=brown_gut_freqdist):\n",
        "  if token not in brown_gut_freqdist:\n",
        "    return 0\n",
        "  else:\n",
        "    return brown_gut_freqdist[token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xNbroRA3854O",
        "outputId": "4d71f2b3-181f-4b99-bb34-457739c7d3d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Adminadvert,\" \"infelicitious\"---a bit pretentious, no?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "from nltk.parse.nonprojectivedependencyparser import nonprojective_conll_parse_demo\n",
        "def COMMENT_scold_rare_word(inputtext):\n",
        "  toks = [tok.lower() for tok,tag in toktag(inputtext) if tag[0] in \"NJV\"]\n",
        "  tok_count = [(tok,get_count(tok)) for tok in toks]\n",
        "  #print(tok_count)\n",
        "  rare_toks = [t for t,c in tok_count if c<min_count_of_word]\n",
        "  critique_word = random.choice([\"affected\",\"pretentious\"])\n",
        "  virtue_word = random.choice([\"common\",\"plain\",\"unassuming\",\"simple\",\"simple and confident\"])\n",
        "  if len(rare_toks)==0:\n",
        "    return None\n",
        "  else:\n",
        "    rare_toks[0]=rare_toks[0].title()\n",
        "    if len(rare_toks)==1:\n",
        "      if random.random()>.5:\n",
        "        return \"\\\"%s\\\" is a bit too %s.  Why not something more %s?\" % (rare_toks[0],critique_word,virtue_word)\n",
        "      else:\n",
        "        return \"\\\"%s\\\" is a bit too %s.  A rare word does not make a rare poem.\" % (rare_toks[0],critique_word)\n",
        "    else:\n",
        "      return \"\\\"%s\\\"---a bit %s, no?\" % (\",\\\" \\\"\".join(rare_toks),critique_word)\n",
        "\n",
        "  \n",
        "COMMENT_scold_rare_word(\"I will adminadvert against my infelicitious fate.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEtlxaNJidRT"
      },
      "source": [
        "## Meta-function\n",
        "\n",
        "Combine individual functions into writing interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQjXeqn1j47d",
        "outputId": "53f270fd-fbf7-44ba-e368-cc520bb833bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function __main__.COMMENT_NN_recommendation(line)>,\n",
              " <function __main__.COMMENT_ban_pos(text)>,\n",
              " <function __main__.COMMENT_chunk_recommendation(text)>,\n",
              " <function __main__.COMMENT_extend_line(inputtext)>,\n",
              " <function __main__.COMMENT_fix_a_word(text)>,\n",
              " <function __main__.COMMENT_flip(text)>,\n",
              " <function __main__.COMMENT_google_suggestion(text)>,\n",
              " <function __main__.COMMENT_on_grammar_not_used(text, tests=[<function number_test at 0x7f4e99ea0790>, <function future_test at 0x7f4e99ea0310>, <function conditional_test at 0x7f4e99ea0ee0>, <function preposition_test at 0x7f4e99ea0670>, <function comp_super_adj_test at 0x7f4e99ea0820>, <function personal_test at 0x7f4e99ea0430>])>,\n",
              " <function __main__.COMMENT_on_line_length(text)>,\n",
              " <function __main__.COMMENT_purpose_of_poetry(inputtext=None)>,\n",
              " <function __main__.COMMENT_recommend_parts(inputtext=None)>,\n",
              " <function __main__.COMMENT_remove_letter(text)>,\n",
              " <function __main__.COMMENT_replace_word(text)>,\n",
              " <function __main__.COMMENT_scold_rare_word(inputtext)>,\n",
              " <function __main__.COMMENT_solicit_proper_noun(text)>,\n",
              " <function __main__.COMMENT_suggest_key_word(inputtext=None)>,\n",
              " <function __main__.COMMENT_suggest_rhyme(text)>,\n",
              " <function __main__.COMMENT_test_against_banned_topics(text, banned_topics=['industrial', 'body', 'face', 'religion', 'writing', 'finance', 'political', 'shopping', 'lustrous', 'darkness', 'music', 'romance', 'death', 'sport', 'school', 'furniture', 'kinfolk', 'nature', 'food', 'digital', 'negative', 'urban', 'violent', 'ocean', 'bird', 'celestial', 'architectural', 'war', 'science'])>,\n",
              " <function __main__.COMMENT_with_wikipedia(text)>]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "import inspect\n",
        "import types\n",
        "from os.path import join\n",
        "\n",
        "def is_local(object):\n",
        "    return isinstance(object, types.FunctionType) and object.__module__ == __name__\n",
        "\n",
        "import sys\n",
        "funcs = [value for name, value in inspect.getmembers(sys.modules[__name__], predicate=is_local) if name.startswith(\"COMMENT_\")]\n",
        "funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jVFUsD--rpI",
        "outputId": "fbe696bd-8431-4cd0-a2ef-792d2ebf0241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "len(funcs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Zt6GaZXwrTZc"
      },
      "outputs": [],
      "source": [
        "faces = \"🙋🏾‍♂️ 👨🏼‍🎨 🙎🏻‍♂️ 🙎🏼‍♀️ 🤦🏾  🤦🏻‍♀️ 👨🏻‍🌾 🕵🏻‍♀️ 🧝🏿‍♂️ 🙍🏻‍♀️ 👨🏼‍💻 🙅🏼‍♂️ 🧕🏼 🧑🏽‍💼 🧑🏼‍🏫 👨🏽‍💼 👨🏿‍🎤 👩🏽‍💼 🤵🏻 💁🏼‍♂️ 💁🏽‍♀️\".split()\n",
        "func2face = {func.__name__:face for func,face in list(zip(funcs,faces[:len(funcs)]))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IccIqlMF8Mwk",
        "outputId": "250f6104-fb09-45ba-fe52-2c211bea8853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function __main__.COMMENT_extend_line(inputtext)>,\n",
              " <function __main__.COMMENT_with_wikipedia(text)>,\n",
              " <function __main__.COMMENT_recommend_parts(inputtext=None)>,\n",
              " <function __main__.COMMENT_suggest_rhyme(text)>,\n",
              " <function __main__.COMMENT_test_against_banned_topics(text, banned_topics=['industrial', 'body', 'face', 'religion', 'writing', 'finance', 'political', 'shopping', 'lustrous', 'darkness', 'music', 'romance', 'death', 'sport', 'school', 'furniture', 'kinfolk', 'nature', 'food', 'digital', 'negative', 'urban', 'violent', 'ocean', 'bird', 'celestial', 'architectural', 'war', 'science'])>,\n",
              " <function __main__.COMMENT_scold_rare_word(inputtext)>,\n",
              " <function __main__.COMMENT_remove_letter(text)>,\n",
              " <function __main__.COMMENT_replace_word(text)>,\n",
              " <function __main__.COMMENT_ban_pos(text)>,\n",
              " <function __main__.COMMENT_chunk_recommendation(text)>,\n",
              " <function __main__.COMMENT_NN_recommendation(line)>]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "funcs_sample = randrand(funcs,min=10)\n",
        "funcs_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "UC2vPGQn9-ED"
      },
      "outputs": [],
      "source": [
        "faces_sample = [func2face[f.__name__] for f in funcs_sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwurLCaN5LQM",
        "outputId": "408d4fed-02f7-4a3d-8f53-24b1762db36b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "repeated_funcs = []\n",
        "\n",
        "for f in funcs_sample:\n",
        "  times_to_repeat = random.randint(0,50)\n",
        "  temp_f = f\n",
        "  for i in range(times_to_repeat):\n",
        "    repeated_funcs.append(temp_f)\n",
        "\n",
        "funcs_sample_multiplied = funcs_sample+repeated_funcs\n",
        "len(funcs_sample_multiplied)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "hJAGixvcTJjl"
      },
      "outputs": [],
      "source": [
        "random.shuffle(funcs_sample_multiplied)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "M9hlkNDXr1k5",
        "outputId": "a274cbcb-de8a-4934-c41d-2b125f2995b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~L O T U S C H O R U S W O R K S H O P~\n",
            "\n",
            "                 🌸\n",
            "a γυμνάσιον\n",
            "\n",
            "***************************************\n",
            "\n",
            "INSTRUCTIONS:\n",
            " - write a sentence of poetry\n",
            " - receive feedback\n",
            " - revise your sentence accordingly\n",
            " - repeat\n",
            " - type \"quit\" to quit\n",
            "\n",
            "***************************************\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-5a21f2d07c0c>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseen_line\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "print(\"~L O T U S C H O R U S W O R K S H O P~\")\n",
        "print(\"\")\n",
        "print(\"                 🌸\")\n",
        "print(\"a γυμνάσιον\")\n",
        "print(\"\")\n",
        "print(\"*\"*39)\n",
        "print(\"\")\n",
        "print (\"INSTRUCTIONS:\")\n",
        "print (\" - write a sentence of poetry\")\n",
        "print (\" - receive feedback\")\n",
        "print (\" - revise your sentence accordingly\")\n",
        "print (\" - repeat\")\n",
        "print (' - type \"quit\" to quit')\n",
        "print(\"\")\n",
        "print(\"*\"*39)\n",
        "\n",
        "max_comments = random.randrange(2,8)\n",
        "max_comments = 8\n",
        "\n",
        "seen_line = False\n",
        "\n",
        "first_responses = [\"Well revised...now keep going, write a new sentence.\",\"Good. Now write another sentence.\"]\n",
        "first_responses.append(\"See how your verse becomes more %s?\" % random.choice(['true','dense','perfect','elemental','cerebral','muscular','liberated','ordered','like you','unlike you','immortal and free']))\n",
        "first_responses.append(\"You have earned this symbol of your %s: 🌸\" % random.choice(['growth','selflessness','openness','purity']))\n",
        "first_responses = [\"   👤:\"+i for i in first_responses]\n",
        "\n",
        "recent_funcs = [] ## will be list of lists\n",
        "cool_off = 2 ## times after using a function it will be unavailable\n",
        "\n",
        "how_critical = [True]+[False]*random.randint(1,10) ## how often it will be satisfied without changes\n",
        "\n",
        "while True:\n",
        "  comments = []\n",
        "  used_funcs = []\n",
        "  user_input=\"\"\n",
        "  ## handle non-input\n",
        "  while user_input==\"\":\n",
        "    if seen_line==False:\n",
        "      user_input = input(\">\")\n",
        "    else:\n",
        "      user_input = input(\">\")\n",
        "  if user_input.lower() in [\"quit\",\"exit\"]:\n",
        "    break\n",
        "  if (seen_line==False): ## only offer feedback once\n",
        "    if (random.choice(how_critical) and len(first_responses)==0):\n",
        "      print(\"   👤:Not bad.  Go on.\")\n",
        "      print(\"\")\n",
        "    else:\n",
        "      seen_line = True # flip\n",
        "      random.shuffle(funcs)\n",
        "      ## print(recent_funcs)\n",
        "      recent_funcs_flat = list(itertools.chain(*recent_funcs))\n",
        "      for f in funcs_sample_multiplied: \n",
        "        #print(f)\n",
        "        if (f not in used_funcs and f not in recent_funcs_flat): \n",
        "          result = f(user_input)\n",
        "          if result!=None:\n",
        "            result = func2face[f.__name__]+\":\"+result\n",
        "            comments.append(result)\n",
        "            used_funcs.append(f)\n",
        "          if len(comments)==max_comments:\n",
        "            break\n",
        "          if (len(comments)>0 and random.choice([True,False,False,False,False,False,False])): ## don't always to go max\n",
        "            break\n",
        "      ## don't always print max \n",
        "      # if len(comments)!=0:\n",
        "      #   comments_maybe_not_all = [comments[0]] ## always print 1st one\n",
        "      #   for i in comments[1:]: ## maybe add the rest\n",
        "      #     if random.choice([True,False,False,False]):\n",
        "      #       comments_maybe_not_all.append(i)\n",
        "      #     else:\n",
        "      #       break\n",
        "      ## print out\n",
        "      if len(comments)==0:  ## fallback if no successful comments\n",
        "        if random.choice([True,True,False]):\n",
        "          print(\"   👤:You must defeat yourself by becoming more like yourself.\")\n",
        "        else:\n",
        "          seen_line = False\n",
        "          print(\"   👤:Good enough.  Go on.\")\n",
        "          print(\"\")\n",
        "      else: ## typical\n",
        "        for c in comments:\n",
        "          print(\"   %s\" % c)\n",
        "      ## keep track of used functions\n",
        "      recent_funcs.append(used_funcs)\n",
        "      if len(recent_funcs)>cool_off:\n",
        "        recent_funcs = recent_funcs[-cool_off:] ## get last n\n",
        "  else:\n",
        "    seen_line=False\n",
        "    if len(first_responses)!=0:\n",
        "      response = first_responses.pop(0)\n",
        "    else:\n",
        "      if random.choice([True,True,False]):\n",
        "        response = \"   👤:\"+random.choice([\"Good.\",\"Much better.\",\"Yes, better.\",\"Nice\",\"👍\",\"Well revised.\",\"Go on...\",\"Go on...\"])\n",
        "      else:\n",
        "        gift = \"👤:For your efforts, please take this: %s\" % random.choice(\"🌼 🌸 🌸 🌸 🌸 🌸 💐 🌺 🌷 🌻 🥀\".split(\" \"))\n",
        "        response = \"   \"+gift\n",
        "    print(response)\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03-I4xcp-JQJ"
      },
      "source": [
        "***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}